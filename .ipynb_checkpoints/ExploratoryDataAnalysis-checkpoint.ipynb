{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "#### 1.1 Check for missing data and rectify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train_df.tweet.isna().any())\n",
    "print(train_df.tweet.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing data present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = train_df['tweet']\n",
    "test_df['cleaned_text'] = test_df['tweet']\n",
    "\n",
    "# get the hashtags\n",
    "def getHashTags(text):\n",
    "    tags = ''\n",
    "    for word in text.split():\n",
    "        if word.startswith('#'):\n",
    "            tags += (' ' + word[1:])\n",
    "            \n",
    "    return tags.strip()\n",
    "\n",
    "train_df['hashTags'] = train_df.cleaned_text.apply(lambda row: getHashTags(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove url\n",
    "# train_df['cleaned_text'] = train_df.cleaned_text.apply(lambda text : ' '.join([word for word in str(text).split() if not ('http' in word or 'https' in word)]))\n",
    "train_df['cleaned_text'] = train_df.cleaned_text.apply(lambda text : re.sub(r'http\\S+', '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove apostrophes\n",
    "\n",
    "def removeApostrophes(text):\n",
    "    aposMap = {\n",
    "        \"'s\": ' is',\n",
    "        \"'re\" : ' are',\n",
    "        \"'m\" : ' am',\n",
    "        \"can't\" : 'cannot',\n",
    "        \"ain't\" : 'is not',\n",
    "        \"n't\" : ' not'\n",
    "    }\n",
    "    \n",
    "    for apos in aposMap:\n",
    "        if apos in text:\n",
    "            text = text.replace(apos,aposMap[apos])\n",
    "    \n",
    "    return text\n",
    "\n",
    "train_df['cleaned_text'] = train_df.cleaned_text.apply(lambda text : removeApostrophes(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding decoding\n",
    "\n",
    "train_df['cleaned_text'] = train_df.cleaned_text.apply(lambda text : text.encode('ascii','ignore').decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove punctuations\n",
    "import re\n",
    "\n",
    "def removePunctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text)\n",
    "\n",
    "train_df['cleaned_text'] = train_df.cleaned_text.apply(lambda row: removePunctuations(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "from nltk.corpus import stopwords \n",
    "# from wordcloud import STOPWORDS\n",
    "stop_words = set(stopwords.words('english')) \n",
    "train_df['cleaned_text'] = train_df.cleaned_text.apply(lambda text : ' '.join([word for word in text.split() if not word in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#model   i love u take with u all the time in ur!!!   \n"
     ]
    }
   ],
   "source": [
    "test1 = '#model   i love u take with u all the time in urÃ°ÂŸÂ“Â±!!! Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘Â…Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦  '\n",
    "\n",
    "test1 = decodeEncoder(test1)\n",
    "\n",
    "print(test1.decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>hashTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>user user thanks lyft credit cannot use cause ...</td>\n",
       "      <td>lyft disapointed getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>22 huge fan fare big talking leave chaos pay d...</td>\n",
       "      <td>allshowandnogo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>user camping tomorrow user user user user user...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>next school year year exams cannot think schoo...</td>\n",
       "      <td>school exams hate imagine actorslife revolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>love land allin cavs champions cleveland cleve...</td>\n",
       "      <td>allin cavs champions cleveland clevelandcavaliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>user user welcome gr8</td>\n",
       "      <td>gr8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "      <td>ireland consumer price index mom climbed previ...</td>\n",
       "      <td>ireland blog silver gold forex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "      <td>selfish orlando standwithorlando pulseshooting...</td>\n",
       "      <td>orlando standwithorlando pulseshooting orlando...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet  \\\n",
       "0    1      0   @user when a father is dysfunctional and is s...   \n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2    3      0                                bihday your majesty   \n",
       "3    4      0  #model   i love u take with u all the time in ...   \n",
       "4    5      0             factsguide: society now    #motivation   \n",
       "5    6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6    7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7    8      0  the next school year is the year for exams.ð...   \n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "10  11      0   â #ireland consumer price index (mom) climb...   \n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...   \n",
       "\n",
       "                                         cleaned_text  \\\n",
       "0   user father dysfunctional selfish drags kids d...   \n",
       "1   user user thanks lyft credit cannot use cause ...   \n",
       "2                                      bihday majesty   \n",
       "3                         model love u take u time ur   \n",
       "4                       factsguide society motivation   \n",
       "5   22 huge fan fare big talking leave chaos pay d...   \n",
       "6   user camping tomorrow user user user user user...   \n",
       "7   next school year year exams cannot think schoo...   \n",
       "8   love land allin cavs champions cleveland cleve...   \n",
       "9                               user user welcome gr8   \n",
       "10  ireland consumer price index mom climbed previ...   \n",
       "11  selfish orlando standwithorlando pulseshooting...   \n",
       "\n",
       "                                             hashTags  \n",
       "0                                                 run  \n",
       "1                         lyft disapointed getthanked  \n",
       "2                                                      \n",
       "3                                               model  \n",
       "4                                          motivation  \n",
       "5                                      allshowandnogo  \n",
       "6                                                      \n",
       "7   school exams hate imagine actorslife revolutio...  \n",
       "8   allin cavs champions cleveland clevelandcavaliers  \n",
       "9                                                 gr8  \n",
       "10                     ireland blog silver gold forex  \n",
       "11  orlando standwithorlando pulseshooting orlando...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
